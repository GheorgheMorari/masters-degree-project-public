{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:34:06.713210Z",
     "start_time": "2024-12-19T11:34:05.604515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from masters_degree_project.adapters.llm_adapter import LLMAdapter\n",
    "\n",
    "llm_adapter = LLMAdapter(base_url=\"http://localhost:8085/v1\", api_key=\"masters_degree_project\",\n",
    "                         model_name=\"gpt-3.5-turbo\")\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"masters_degree_project\"\n",
    "os.environ['OPENAI_API_BASE'] = \"http://localhost:8085/v1\"\n",
    "os.environ['USER_AGENT'] = 'myagent'"
   ],
   "id": "2d1d03bf033493dd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-19T11:34:07.564543Z",
     "start_time": "2024-12-19T11:34:06.715527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from masters_degree_project.services.behaviour_indexing import behaviour_indexing\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from masters_degree_project.adapters.custom_openai_embeddings import LLAMA_CPP_Compatible_OpenAIEmbeddings as OpenAIEmbeddings\n",
    "import bs4\n",
    "\n",
    "\n",
    "# Load Documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "# modified_splits = []\n",
    "# for split in tqdm(splits):\n",
    "#     modified_splits.append(behaviour_indexing(split.page_content, llm_adapter))"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:34:10.940763Z",
     "start_time": "2024-12-19T11:34:07.728334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n"
   ],
   "id": "90fecc2331862e1c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:34:15.800960Z",
     "start_time": "2024-12-19T11:34:10.946737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from masters_degree_project.services.behaviour_indexing import behaviour_indexing\n",
    "\n",
    "behaviour_indexing(splits[98].page_content, llm_adapter)"
   ],
   "id": "e7381b9e76026dcb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"virtual characters' interaction within a simulated setting\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:41:36.419873Z",
     "start_time": "2024-12-19T11:34:15.882042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from masters_degree_project.adapters.behaviour_indexing_embeddings import BehaviourIndexingEmbeddings\n",
    "\n",
    "modified_vectorstore = FAISS.from_documents(documents=splits, embedding=BehaviourIndexingEmbeddings(llm_adapter=llm_adapter, openai_embeddings=OpenAIEmbeddings()))\n",
    "\n",
    "modified_retriever = modified_vectorstore.as_retriever()"
   ],
   "id": "d6ba97add1cf2e88",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [07:18<00:00,  2.58s/it]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:41:50.064558Z",
     "start_time": "2024-12-19T11:41:48.962470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ],
   "id": "a9138950a19ee638",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmora\\Documents\\GitHub\\masters-degree-project\\venv\\Lib\\site-packages\\langsmith\\client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:42:01.777217Z",
     "start_time": "2024-12-19T11:42:01.773257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "modified_rag_chain = (\n",
    "        {\"context\": modified_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ],
   "id": "664cf1c4add6d9f8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:51:41.038221Z",
     "start_time": "2024-12-19T11:51:37.782721Z"
    }
   },
   "cell_type": "code",
   "source": "rag_chain.invoke(\"What is Chain of Hindsight?\")",
   "id": "5a5853da8ee98b4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Chain of Hindsight (CoH) is a technique that improves model outputs by presenting it with past outputs annotated with human feedback. It encourages the model to learn from its previous mistakes and utilize this information for better performance on complex tasks. The method involves using a sequence of past outputs, each labeled with ratings and corresponding explanations (CoT).'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:51:45.704133Z",
     "start_time": "2024-12-19T11:51:41.193894Z"
    }
   },
   "cell_type": "code",
   "source": "modified_rag_chain.invoke(\"What is Chain of Hindsight?\")",
   "id": "6446c5870fba0368",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I\\'m sorry, but based on the provided context, there is no information about \"Chain of Hindsight.\" The given text discusses memory types in human brains, generative agent architecture, proof-of-concept examples, and challenges related to LLM agents. Therefore, I don\\'t know about Chain of Hindsight from this context.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:54:12.806436Z",
     "start_time": "2024-12-19T11:54:10.085447Z"
    }
   },
   "cell_type": "code",
   "source": "rag_chain.invoke(\"How is it called when an agent breaks down large tasks into smaller tasks?\")",
   "id": "2cc3ccecf5e13a64",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The process of breaking down large tasks into smaller, manageable subtasks is called task decomposition. This approach allows agents to efficiently handle complex tasks by organizing them into simpler components.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:54:19.703116Z",
     "start_time": "2024-12-19T11:54:15.437970Z"
    }
   },
   "cell_type": "code",
   "source": "modified_rag_chain.invoke(\"How is it called when an agent breaks down large tasks into smaller tasks?\")",
   "id": "bdc962fbc3439ced",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The process of breaking down large tasks into smaller, manageable subtasks is called \"task decomposition.\" This approach allows agents to handle complex tasks more efficiently by organizing them into a sequence of simpler steps or goals.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:57:59.253787Z",
     "start_time": "2024-12-19T11:57:55.985322Z"
    }
   },
   "cell_type": "code",
   "source": "rag_chain.invoke(\"The LLM is provided with a list of tool names\")",
   "id": "a359d00e79081f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes, an LLM (Language Learning Model) can be provided with a list of tool names along with their descriptions and input/output details to enhance its capabilities when answering user prompts using external tools like Plugins or API calls. This approach is exemplified by models such as TALM and Toolformer that are fine-tuned for tool usage.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T11:58:06.133353Z",
     "start_time": "2024-12-19T11:58:01.479843Z"
    }
   },
   "cell_type": "code",
   "source": "modified_rag_chain.invoke(\"The LLM is provided with a list of tool names\")",
   "id": "72dbd00cf9a25855",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The LLM is provided with a list of tool names, their utility descriptions, and input/output details to assist in answering user prompts using the ReAct format. Tools include executing Python files, generating images, sending tweets, performing no action, or completing tasks.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T12:04:40.510955Z",
     "start_time": "2024-12-19T12:04:37.335133Z"
    }
   },
   "cell_type": "code",
   "source": "rag_chain.invoke(\"develop a novel anticancer drug step by step\")",
   "id": "af6312cdf29a93a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' To develop a novel anticancer drug step by step using ChemCrow, start by researching current trends in anticancer drug discovery. Then select an appropriate target for the drug and request a suitable scaffold that targets these compounds. Finally, attempt to synthesize the identified compound using organic synthesis tools integrated within LangChain workflow.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T12:04:45.946321Z",
     "start_time": "2024-12-19T12:04:40.655733Z"
    }
   },
   "cell_type": "code",
   "source": "modified_rag_chain.invoke(\"develop a novel anticancer drug step by step\")",
   "id": "e97f33b81c858abc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" To develop a novel anticancer drug step by step, first identify an oncogenic target relevant to cancer progression. Then select a suitable scaffold that can interact with this target effectively. Finally, design and synthesize the compound based on computational models and experimental validation for efficacy against the chosen target.\\n\\nNote: The provided context does not directly relate to anticancer drug development but rather discusses risks associated with illicit drugs and bioweapons. However, I've tailored a response using relevant steps in drug discovery as per your request.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
